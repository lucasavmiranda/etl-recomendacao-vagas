{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282847d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ETL monolítico para rodar no Colab\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# =========================\n",
    "# Configurações\n",
    "# =========================\n",
    "class Config:\n",
    "    DATA_DIR = \"data\"\n",
    "    USERS_CSV = os.path.join(DATA_DIR, \"users.csv\")\n",
    "    JOBS_CSV = os.path.join(DATA_DIR, \"jobs.csv\")\n",
    "    USER_NEWS_CSV = os.path.join(DATA_DIR, \"user_news.csv\")\n",
    "    ICON_URL = \"https://digitalinnovationone.github.io/santander-dev-week-2023-api/icons/credit.svg\"\n",
    "    SCORE_PER_SKILL = 1\n",
    "    MIN_SCORE = 2\n",
    "    MAX_RECS_PER_USER = 2\n",
    "\n",
    "# =========================\n",
    "# Utils\n",
    "# =========================\n",
    "def log(msg):\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{ts}] {msg}\")\n",
    "\n",
    "def normalize_skills(text):\n",
    "    if pd.isna(text) or str(text).strip() == \"\":\n",
    "        return []\n",
    "    return [s.strip().lower() for s in str(text).split(\";\") if s.strip()]\n",
    "\n",
    "def validate_required_columns(df, required, filename):\n",
    "    cols = set(df.columns)\n",
    "    missing = required - cols\n",
    "    if missing:\n",
    "        raise ValueError(f\"{filename} está faltando colunas: {missing}\")\n",
    "\n",
    "# =========================\n",
    "# Extract\n",
    "# =========================\n",
    "def extract_users(path):\n",
    "    log(f\"Lendo {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "    validate_required_columns(df, {\"user_id\",\"name\",\"skills\"}, \"users.csv\")\n",
    "    df[\"skills_norm\"] = df[\"skills\"].apply(normalize_skills)\n",
    "    return df\n",
    "\n",
    "def extract_jobs(path):\n",
    "    log(f\"Lendo {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "    validate_required_columns(df, {\"job_id\",\"title\",\"company\",\"required_skills\",\"location\",\"level\"}, \"jobs.csv\")\n",
    "    df[\"required_skills_norm\"] = df[\"required_skills\"].apply(normalize_skills)\n",
    "    return df\n",
    "\n",
    "def extract_user_news(path):\n",
    "    log(f\"Verificando saída {path}\")\n",
    "    if not os.path.exists(path):\n",
    "        pd.DataFrame(columns=[\"user_id\",\"news_id\",\"icon\",\"description\",\"created_at\"]).to_csv(path, index=False)\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "# =========================\n",
    "# Transform\n",
    "# =========================\n",
    "def score_match(user_skills, job_skills):\n",
    "    overlap = set(user_skills) & set(job_skills)\n",
    "    return len(overlap) * Config.SCORE_PER_SKILL, sorted(list(overlap))\n",
    "\n",
    "def build_message(user_name, job, score, matched_skills):\n",
    "    skills_str = \", \".join(matched_skills) if matched_skills else \"—\"\n",
    "    return (\n",
    "        f\"{user_name}, esta vaga pode ser ideal para você: {job['title']} em {job['company']} \"\n",
    "        f\"({job['location']}, nível {job['level']}). Compatibilidade {score} \"\n",
    "        f\"pelas habilidades: {skills_str}.\"\n",
    "    )\n",
    "\n",
    "def recommend_jobs_for_user(user_row, jobs_df):\n",
    "    user_skills = user_row[\"skills_norm\"]\n",
    "    scored = []\n",
    "    for _, job in jobs_df.iterrows():\n",
    "        score, matched = score_match(user_skills, job[\"required_skills_norm\"])\n",
    "        if score >= Config.MIN_SCORE:\n",
    "            scored.append({\"job\": job, \"score\": score, \"matched_skills\": matched})\n",
    "    scored.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    return scored[:Config.MAX_RECS_PER_USER]\n",
    "\n",
    "# =========================\n",
    "# Load\n",
    "# =========================\n",
    "def next_news_id(existing_df):\n",
    "    if existing_df.empty:\n",
    "        return 1\n",
    "    return int(existing_df[\"news_id\"].max()) + 1\n",
    "\n",
    "def news_exists(existing_df, user_id, description):\n",
    "    subset = existing_df[(existing_df[\"user_id\"] == user_id) & (existing_df[\"description\"] == description)]\n",
    "    return not subset.empty\n",
    "\n",
    "def append_news(existing_df, user_id, description, icon_url=Config.ICON_URL):\n",
    "    if news_exists(existing_df, user_id, description):\n",
    "        log(f\"News já existe (user_id={user_id}). Pulando.\")\n",
    "        return existing_df\n",
    "    nid = next_news_id(existing_df)\n",
    "    new_row = {\n",
    "        \"user_id\": user_id,\n",
    "        \"news_id\": nid,\n",
    "        \"icon\": icon_url,\n",
    "        \"description\": description,\n",
    "        \"created_at\": datetime.now().isoformat(timespec=\"seconds\")\n",
    "    }\n",
    "    return pd.concat([existing_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "def save_news(df, path):\n",
    "    df.to_csv(path, index=False)\n",
    "    log(f\"Salvo em {path}\")\n",
    "\n",
    "# =========================\n",
    "# Pipeline\n",
    "# =========================\n",
    "def run_pipeline():\n",
    "    log(\"Início do ETL\")\n",
    "    users_df = extract_users(Config.USERS_CSV)\n",
    "    jobs_df = extract_jobs(Config.JOBS_CSV)\n",
    "    news_df = extract_user_news(Config.USER_NEWS_CSV)\n",
    "\n",
    "    total_msgs = 0\n",
    "    for _, user in users_df.iterrows():\n",
    "        recs = recommend_jobs_for_user(user, jobs_df)\n",
    "        if not recs:\n",
    "            log(f\"Sem recomendações para {user['name']}.\")\n",
    "            continue\n",
    "        for rec in recs:\n",
    "            msg = build_message(user[\"name\"], rec[\"job\"], rec[\"score\"], rec[\"matched_skills\"])\n",
    "            news_df = append_news(news_df, user[\"user_id\"], msg, Config.ICON_URL)\n",
    "            total_msgs += 1\n",
    "\n",
    "    save_news(news_df, Config.USER_NEWS_CSV)\n",
    "    log(f\"ETL finalizado. Mensagens geradas: {total_msgs}\")\n",
    "    return news_df\n",
    "\n",
    "# Executa e mostra resultado\n",
    "output_df = run_pipeline()\n",
    "output_df.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
